\documentclass[12pt]{article}

\usepackage{hyperref}
\usepackage{setspace}
\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage{indentfirst}
\bibliographystyle{plainnat}
\newcommand{\superscript}[1]{\ensuremath{^{\textrm{#1}}}}
\newcommand{\subscript}[1]{\ensuremath{_{\textrm{#1}}}}

\begin{document}
\title{Literature Review}
\author{Andrew Valencik}
\date{January 29th, 2014}
\maketitle
\tableofcontents
\listoffigures
\begin{doublespacing}

%%% Begin Introduction
%%% General intro
% - Nuclear Science
% - Database
% - Data Mining
\pagebreak
\section{Introduction}

The body of nuclear science literature is extensive, mature, and well categorized by the National Nuclear Data Center \citep{Kurgan200603} which provides the opportunity for knowledge discovery on the literature's meta data.
This process should reveal trends in the collective scientific study of nuclear structure, processes, and detection.
Additionally, categorizing trends may provide predictive power in determining a worthwhile area of study or application of a technique.
This work is a cross disciplinary work, combining data mining technique with domain knowledge in nuclear physics. 
As such, two major sections will be reviewed, knowledge discovery and nuclear science.

Knowledge discovery and data mining provides the techniques to study and analyze the Nuclear Science References database.
Data representation and classification are necessary steps to establish the structures within the database, i.e.\ papers, fields, or genres.
Cluster analysis is used to group data elements based on rules.
Though many techniques exist, K-means will be looked at in detail.

An introductory review of radiation and semiconductor detectors is given as these topics will serve as the domain knowledge for the knowledge discovery process. 


%%% Knowledge Discovery
% - Intro to KD and DM
% - Selected technique: Clustering and Classification
% - Selected technique: Sentiment Analysis
\pagebreak
\section{Knowledge Discovery}
Knowledge Discovery and Data Mining refers to the field of techniques and tools for finding useful trends and patterns in large volumes of data.
This encompasses discovering new phenomena and enhancing our existing knowledge from data sources.
The traditional process begins with data selection, preprocessing of that data and any necessary transformations, traditional "Data Mining", and finally the interpretation and explanation of results.

\subsection{Classification and Clustering}
Classification and clustering are related approaches to organizing data elements into groups for further analysis.
Classification is the process of deciding what group a particular datum should most optimally belong to.
This is a supervised process that requires domain specific knowledge.

Clustering is the grouping of multiple data points such that those belonging to a group are more similar in some manner than those outside of that group.
Cluster analysis is unsupervised learning.
Clustering can be broken into two main groups, hierarchical and partitional. \citep{Jain2010651}
Partitional methods include centroid based clustering where data elements are assigned to the cluster with the closest centroid.
Hierarchical methods seek to build a hierarchy of clusters.

\subsubsection{K-means Clustering}
K-means clustering is a cluster analysis technique that can group data objects in $K$ clusters based on minimizing their distances with respect to cluster centroids.
K-means is a partitional clustering algorithm.

Say we have a finite set of objects,  $X = {x_1, x_2, ..., x_n}$ where each is a data object in $d$ dimensions.
We can create $k$ clusters $C = {c_1, c_2, ..., c_k}$ where $k <= n$.
The process starts by randomly choosing $k$ points, ${x_1, ..., x_k}$ to be the centroids of a cluster.
Iterate over each object $x$ and assign it to a cluster $c$ based on the minimization of some parameter, for now, Euclidean distance.
The new centroids are now computed and the process is repeated until cluster stability is achieved.
The goal is to minimize the total sum of squared errors between the centroids and all objects. 
\begin{equation} \label{kmeans}
J(C) = \sum^K_{k=1} \sum_{x_i \in c_k} \left| x_i - \mu_k \right| ^2
\end{equation}

\begin{figure}[!hb]
    \centering
    \includegraphics[width=\linewidth]{kmeansJain.pdf}
    \caption{Step by step illustration of K-means algorithm. (a) The initial input data. (b) Three seed points are chosen as the starting 'centroids' and the data points are assigned to the cluster with the closest seed point. (c) (d) The centroids of the new clusters are calculated, and data labels updated; (e) the iteration stops when the clusters converge.}
    \label{fig:K-Means-Jain}
\end{figure}

Three parameters for K-means must be specified initially, the number of clusters, initial centroid guesses, and the distance metric.
The metric is the function on a space that describes how two points differ from one another, i.e. distance.
Euclidean distance is typically used, leading to ball or sphere shaped clusters. \citep{Jain2010651}
Other metrics may have different results, like the Mahalanobis distance metric which leads to hyper ellipsoidal clusters. \citep{MaoJain1996}
The choice of metric may be domain specific; the Itakura-Saito distance represents the error between an auditory spectrum and its approximate, it is used in speech processing. \citep{chan2008advances}

The chosen number of clusters has a huge impact on the data partitions.
Some heuristics exist to aid in determining an optimal $k$. \citep{tibshirani2001estimating}
However, in practice, K-means is normally run multiple times with varying $k$ values and the best is selected by a domain expert.


\subsection{Text Mining}
Text mining is an area of analysis that focuses on extracting useful information from unstructured plain text data.
The data to analyze is often natural language text written by humans.
Examples of such data include user reviews of a product or service, customer feedback comments, emails, forum posts, or even academic journal articles.

A simple goal of text mining could be to summarize the input text.
However, this can be abstracted further to 'numericizing' text data for use in an analysis model.

Sentiment analysis is the extraction of subjective information, like opinions, from text data.
This can be accomplished by parsing natural language and quantifying the affectivity of keywords.

\subsubsection{Cosine Similarity}
%https://stackoverflow.com/questions/15173225/how-to-calculate-cosine-similarity-given-2-sentence-strings-python
The K-means discussion above mentioned a few types of distance metrics for use in clustering.
When dealing with text we often use the cosine similarity of two documents to compute their 'distance.
We build a term vector for each document to be analyzed, this is a vector describing the amount of occurrences each word has in the document
Say document one, $d1$, is "The quick brown fox jumped over the lazy dog" and document two, $d2$, is "The brown dog jumped over the brown fox".
We create a term vector for each document, as seen in table \ref{termtable}. 
Often in doing this, very common words like 'the' are omitted.
Equations \ref{d1termvector} and \ref{d2termvector} are the term vectors for each document.
The cosine similarity is the dot product of the two documents divided by the product of their magnitudes (\ref{cosinesimilarity}). \citep{huang2008similarity}

\begin{table} \label{termtable}
    \begin{tabular}{llllllll}
    ~  & quick & brown & fox & jumped & over & lazy & dog \\
    d1 & 1     & 1     & 1   & 1      & 1    & 1    & 1   \\
    d2 & 0     & 2     & 1   & 1      & 1    & 0    & 1   \\
    \end{tabular}
\end{table}

\begin{equation} \label{d1termvector}
d1 = \left< 1, 1, 1, 1, 1, 1, 1 \right>
\end{equation}

\begin{equation} \label{d2termvector}
d2 = \left< 0, 2, 1, 1, 1, 0, 1 \right>
\end{equation}

\begin{equation} \label{cosinesimilarity}
\cos (d1,d1) = \frac{d1 \cdot d2 }{\left| d1 \right| \left| d2 \right|} 
\end{equation}

\begin{equation} \label{cosinesimilarity1}
 d1 \cdot d2 = (1)(0) + (1)(2) + (1)(1) + (1)(1) + (1)(1) + (1)(0) + (1)(1) = 6.0 
\end{equation}

\begin{equation} \label{cosinesimilarity2}
 \left| d1 \right| = \left( (1)^2 + (1)^2 + (1)^2 + (1)^2 + (1)^2 + (1)^2 + (1)^2 \right) ^{\frac{1}{2}} =  2.645751311
\end{equation}

\begin{equation} \label{cosinesimilarity3}
 \left| d2 \right| = \left( (0)^2 + (2)^2 + (1)^2 + (1)^2 + (1)^2 + (0)^2 + (1)^2 \right) ^{\frac{1}{2}} =  2.828427125
\end{equation}

\begin{equation} \label{cosinesimilarityF}
\cos (d1,d2) = \frac{d1 \cdot d2 }{\left| d1 \right| \left| d2 \right|} = \frac{6.0}{\left| 2.645751311 \right| \left| 2.828427125 \right|} = 0.8017837257
\end{equation}

As equation \ref{cosinesimilarityF} shows, the two documents are quite similar, and thus have a high cosine similarity.
When $d1 = d2$ the similarity is 1.0.
This technique is a simple way of numercizing text for further mathematical manipulation and treatment.


%%% Nuclear Science
% - Radiation
% - Selected technique: Semiconductor detectors
\pagebreak
\section{Nuclear Science}
The following review summarizes important concepts in nuclear science related to radiation, and in radiation detection techniques.
The primary body of work referenced for the Radiation and Semiconductor Detectors sections is Glenn Knoll's Radiation Detection and Measurement. \citep{knoll2010radiation}
This is largely due to the maturity of the science discussed. Knoll's work serves just as well, if not better than a topical review of the field.


\subsection{Radiation}
Radiation is the process through which a nuclear system becomes more stable by emission of energy that is in excess to the system's ground state.
This energy emission has multiple types and properties that reveal information about the structure of the parent nuclear system.
The emitted energy from a single nuclear reaction is incredibly tiny when compared to everyday interactions.
Therefore nuclear physics experiments often involve complex radiation detection and data acquisition systems. 

\subsubsection{Alpha Decay}
Alpha, $\alpha$, decay is a type of nuclear decay prevalent in heavy nuclei, in which an alpha particle (helium nucleus), is ejected from the parent nuclide. Alpha emitters are useful in \href{http://cs.smu.ca/~andrew/files/ugthesis/SMU-Thesis-v.1.0.1.pdf}{calibrating} nuclear detectors as they are effectively monoenergetic in terms of their energy resolution. There is a species change associated with alpha decay depicted in the following equation.
The mechanism for alpha decay is Coulomb barrier penetration via \href{https://en.wikipedia.org/wiki/Quantum_tunneling}{quantum tunneling}. The barrier penetration probability is needed to describe the relationship between energy and halflife. Alpha decay can happen alongside larger \href{https://en.wikipedia.org/wiki/Nuclear_fission}{fission breakup} reactions.

\begin{equation} \label{alphaDecayEqn}
^A_Z X \rightarrow ^{A-4}_{Z-2}Y + ^4_2 \alpha
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[trim={6cm 11cm 6cm 11cm},clip]{AlphaDecay-wiki.pdf}
    \caption{Wiki Commons: Alpha Decay Image} %(http://commons.wikimedia.org/wiki/File:Alpha_Decay.svg)
    \label{fig:alphadecay}
\end{figure}

\subsubsection{Beta Decay}
There are three types of beta, $\beta$, decay, beta-minus decay, beta-plus decay, and electron capture. Both beta-minus decay, and beta-plus decay involve the ejection of a beta particle (an \href{http://en.wikipedia.org/wiki/Electron}{electron} or \href{http://en.wikipedia.org/wiki/Positron}{positron}) and a \href{http://en.wikipedia.org/wiki/Neutrino}{neutrino} (or \href{http://en.wikipedia.org/wiki/Antineutrino#Antineutrinos}{antineutrino}). Thus beta decay also produces a species change as described below. \href{https://en.wikipedia.org/wiki/Electron_capture}{Electron capture}, converts a nuclear proton to a neutron by absorbing an orbiting electron.
The neutrinos have a very low interaction probability with matter and are thus not detected directly. The beta particle and the neutrino take away a small amount of momentum from the system, resulting in a minute recoil energy on the daughter nucleus. This recoil energy is generally well below the ionization threshold of the detecting volume and therefore goes unmeasured.
Beta emitters are good sources of fast electrons. A pure beta emitter is one that decays directly to a ground state. The energy spectrum of beta decay is continuous. If monoenergetic electrons are desired, a system that undergoes \href{https://en.wikipedia.org/wiki/Internal_conversion}{internal conversion} is desirable. The two processes are worth mentioning together as some beta emitters will undergo internal conversion after a beta decay event.

\begin{equation} \label{betaMinusDecayEqn}
^A_Z X \rightarrow ^{A}_{Z+1}Y + \beta^{-} + \bar{\nu} \quad \mbox{Beta minus decay}
\end{equation}

\begin{equation} \label{betaPlusDecayEqn}
^A_Z X \rightarrow ^{A}_{Z-1}Y + \beta^{+} + \nu \quad \mbox{Beta plus decay}
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[trim={6cm 11cm 6cm 11cm},clip]{BetaDecay-wiki.pdf}
    \caption{Wiki Commons: Beta Decay Image} %(http://commons.wikimedia.org/wiki/File:Beta_Decay.svg)
    \label{fig:Betadecay}
\end{figure}

\subsubsection{Nuclear Fission}
Nuclear fission is the break up of an unstable nucleus into smaller pieces. These pieces can be quite large (by definition larger than an alpha particle) and can be unstable themselves. Nuclei that undergo fission have a distribution of emitted masses, not a single finite mass as in alpha decay. Nuclear fission is usually accompanied by alpha decay and neutron emission.

\subsubsection{Gamma Radiation}
An unstable nuclear state can decay by emitting a high energy photon called a gamma, $\gamma$, ray. Because the gamma ray is uncharged it is usually detected by observing the effects of its interaction with a detecting volume. In this form of radiation there is no change of species. 
Gamma rays have enough energy to ionize some materials. It is through this process, and the production of \href{https://en.wikipedia.org/wiki/Secondary_emmission}{secondary emission} that gamma rays are detected. Gamma rays can follow beta decay, in which case they have halflife properties from the parent, but reflect energy levels of the daughter nucleus.
Gamma rays can also be produced by an annihilation event where an electron and positron annihilate and produce two gamma rays of 0.511MeV in opposite directions. Because of this, beta-plus decay, which releases positrons, is often accompanied by 0.511MeV gamma rays.

\begin{equation} \label{gammaDecayEqn}
^A_Z X^* \rightarrow ^{A}_{Z}X + ^0_0\gamma \quad \mbox{Gamma decay}
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[trim={6cm 11cm 6cm 11cm},clip]{GammaDecay-wiki.pdf}
    \caption{Wiki Commons: Gamma Decay Image} %(http://commons.wikimedia.org/wiki/File:Gamma_Decay.svg)
    \label{fig:Gammadecay}
\end{figure}

\subsubsection{Neutron Radiation}
Another form of uncharged radiation, neutrons can be detected by the use of an absorber material which emits characteristic energy or ions that are then detected separately.
Absorption of thermal neutrons can prompt the emission of gamma rays from the nucleus.
A good discussion on neutron radiation applications and concepts can be found in Knoll's Radiation Detection and Measurement.

\subsubsection{Propagation}
Over time the energy release from a radioactive source is usually isotropic. In an experimental setup, a solid angle portion may be incident on a [semiconductor detector](semiconductorDetectors). To avoid energy loss through interactions occurring between the source and the detector, the experimental setup is typically under vacuum. 
The penetration depth varies among radiation types. Photons propagate through the \href{https://en.wikipedia.org/wiki/Electromagnetic_field}{electromagnetic field} at the \href{https://en.wikipedia.org/wiki/Speed_of_light}{speed of light}. Other particulate radiation has a velocity dependent on its energy. Typical energies of alpha decay can be stopped by a piece of paper, beta decay by thin films of aluminum, and gamma rays by lead shielding.


\subsection{Semiconductor Detectors}   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A wide range of detectors are available for various forms of radiation.
Papers in this section focus on a specific implementation of a detector and usually describe the architectural setup at a high level.

\subsubsection{Immediate Sources of Energy Loss}

%% Entrance Window
In the case of a HPGe, High Purity Germanium, detector the radiation must pass through a protecting window. 
Materials such as Beryllium or Aluminium may be used in ~1mm thicknesses.\footnote{\url{http://www.physics.fsu.edu/courses/Spring12/PHY3802L/exp4822/aptec_EGPC-.pdf}} 
Their low densities and atomic masses allow some radiation to pass through with little energy loss.
\\

%% Dead Layer
The dead layer is a section of the detecting volume that does not contribute to detecting. 
Incident radiation may lose energy here, and no detection event is registered. 
This effect may be significant for heavy charged particles or weakly penetrating radiation.
The thickness of this layer can be reduced with an applied voltage called a bias voltage.
\\


\subsubsection{Structure of Detector Volume}

%% Crystal Lattice
The radiation begins interacting with the crystal lattice. 
High energy photons impact electrons in the lattice and depart some energy via ionization, atomic excitation, and bremsstrahlung emission. 
\\

%% p-n Junctions
A p-n junction is boundary between a p-type semiconductor and a n-type semiconductor material. 
A n-type semiconductor has been doped to have an excess of electrons. 
Similarly, a p-type semiconductor is implanted with a dopant such that it has an abundance of holes. 
A displacement of charge carries occurs at a p-n junction. 
This is the result of a diffusion force felt by charge carriers near the junction. 
The electrons are attracted from the n-type material towards the p-type material through the Coulomb interaction with the excess hole in the p-type semiconductor. 
Eventually a equilibrium charge distribution is reached, at which there is a potential difference across the junction opposing further diffusion.
\\


\subsubsection{Interactions}
Photoelectric absorption: The photon transfers its energy to an atom, knocking out an electron, typically from the K shell. 
The electron, a photoelectron, has kinetic energy equal to the photon minus the original binding energy of the electron, and a very small amount of recoil energy.

%% Secondary Emissions
The output signal of a detector is reliant on collecting a charge associated with the radiation's interaction with the detecting volume. 
These interactions can excite other particles in the volume that contribute to the overall charge.
Detector materials are designed to favourably allow these interactions and produce a large amount of secondary emissions. 
\\


\subsubsection{Detector Operation}
We make use of a simplified detector model to describe some of the processes involved in detector operation.
Consider some incident radiation on our detecting volume. 
By some process the radiation interacts with the detecting medium and deposits energy which produces a net charge. 
A voltage is applied across the detecting volume, this biases the volume creating an electric field. 
When charge carriers are produced by an interaction, the electron-hole pairs migrate apart, in opposite directions according to the field. 
Without a bias the charge carriers are immobile and will not produce a current at the collection sites.

%% Pulse Mode
A detector can be run in current mode, mean square voltage mode, or pulse mode. 
The pulse mode operation of a detector will be the focus of this study as it best enables the detection of individual radiation quanta by providing information on amplitude and timing.
\\

%% Charge Collection
The bias applied to the detecting volume promotes charge carrying electrons into the conduction band and draws them to the collection sites. 
Holes are also collected, but an opposite collection site.
\\

%% Dead Time
A detector's dead time is the duration after a radiation event before the detector can correctly respond to another event.
There are two models for dead time, paralyzable and nonparalyzable. 
If consecutive events in the detector extend the dead time, it is said to be paralyzable. 
In this behaviour a count rate higher than the inverse of the dead time will completely stop the detection of new events. 
Each radiation interact will restart the dead time of the system and thus no events will be recorded. 
In the nonparalyzable model the dead time is not restarted by an event occurring during the dead time. 
Thus in the limiting case the count rate will be no higher than the inverse of the dead time.
So it is always possible that an 'event' contains multiple incidences of radiation.
\\

\subsubsection{Detector Examples}

The Gamma-Ray Energy Tracking In-beam Nuclear Array, GRETINA, detector modules maximize solid angle coverage and tracking performance while minimizing costs in detector manufacturing. \citep{Paschalis201344}
The energy and point position of each gamma interaction can be reconstructed with high precision, exceeding the capabilities of previous germanium detectors. \citep{Eberth2008283}
%A lengthy and detailed topical review of gamma-ray tracking with Germanium detectors over the last 50 years.
Advancements in growing large Germanium crystals has allowed the very large detectors which are necessary for GRETINAs geometry. \citep{Sangsingkeow2003183}
The detector modules are n-type high purity germanium crystals segmented 36 times.
The testing and acceptance process is important is achieving the energy resolution of 2.2keV at 1333keV.
The digital signal processing has 10 channel inputs, each leading to a 14-bit ADC with a 100MHz sampling rate.
This information is then fed to a Xilinix FPGA which uses a trapezoidal filter to calculate energy, and leading edge and constant fraction discrimination algorithms for timing information.
There are many advantages to using FPGAs in detector electronics, for example the hope of self-triggering systems. \citep{Alberto200999}

%TREND SEGA, detect
SEGA is the first N-type segmented Germanium detector with 85\% $^{76}\mbox{Ge}$ enrichment. \citep{Leviner201466}
 is characterized and evaluated for use in the Majorana collaboration.
The segmented enriched germanium array (SEGA) is applicable to neutrinoless double beta-decay because of the strong energy resolution performance near 2039keV.
SEGA's performance in regards to cross-talk, electronic noise, and resolution make it a viable detector for the search for neutrinoless double beta-decay.
Neutrinoless double beta-decay has yet to be observed, but would show that neutrinos are majorana particles, meaning they are their own antiparticle.
These interactions have incredibly long halflives and are thus very rare.


%%% That's all folks
\pagebreak
\end{doublespacing}

\bibliography{../citationsAPSC.bib}

\end{document}
